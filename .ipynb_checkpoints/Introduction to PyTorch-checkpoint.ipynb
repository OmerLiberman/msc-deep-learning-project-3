{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:43:28.462209Z",
     "start_time": "2022-12-21T06:43:22.001480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:45:03.379538Z",
     "start_time": "2022-12-21T06:45:03.360054Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(1000, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(1000, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(1000)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:800]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[800:]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:45:04.410868Z",
     "start_time": "2022-12-21T06:45:04.391445Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "lr = 1e-1\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:45:06.680989Z",
     "start_time": "2022-12-21T06:45:06.632528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters\n",
    "\n",
    "If we want PyTorch to handle backprop for us, we need to make sure `requires_grad` evaluated to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:46:18.419369Z",
     "start_time": "2022-12-21T06:46:18.407074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9470], requires_grad=True) tensor([-0.7928], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More about computational graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T16:30:02.388336Z",
     "start_time": "2022-12-21T16:30:02.348639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2., requires_grad=True)\n",
      "tensor(3., grad_fn=<AddBackward0>)\n",
      "tensor(-12., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(-2., requires_grad=True)\n",
    "y = torch.tensor( 5., requires_grad=True)\n",
    "z = torch.tensor(-4., requires_grad=True)\n",
    "q = x + y\n",
    "f = q * z\n",
    "print(x)\n",
    "print(q)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T16:30:02.784351Z",
     "start_time": "2022-12-21T16:30:02.760082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q: tensor(3., grad_fn=<AddBackward0>)\n",
      "q.grad: None\n",
      "f: tensor(-12., grad_fn=<MulBackward0>)\n",
      "f.grad: None\n"
     ]
    }
   ],
   "source": [
    "print('q:', q)\n",
    "print('q.grad:', q.retain_grad())\n",
    "print('f:', f)\n",
    "print('f.grad:', f.retain_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T16:30:03.358639Z",
     "start_time": "2022-12-21T16:30:03.338552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad tensor(-4.)\n",
      "y.grad tensor(-4.)\n",
      "z.grad tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "f.backward()\n",
    "print('x.grad', x.grad)\n",
    "print('y.grad', y.grad)\n",
    "print('z.grad', z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:50:12.250226Z",
     "start_time": "2022-12-21T06:50:11.511811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0093], requires_grad=True) tensor([1.9865], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD([a,b], lr=lr)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward prop\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0173], device='cuda:0', requires_grad=True) tensor([1.9844], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD([a,b], lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward prop\n",
    "    yhat = a + b * x_train_tensor\n",
    "    loss = criterion(y_train_tensor, yhat)\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "A model is represented by a python class that inherits from the [Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class from PyTorch. This should feel similar to the homework exercises.\n",
    "\n",
    "Every model needs to implement two functions:\n",
    "1. `__init__(self)`: defines the parameters and layers of the model.\n",
    "2. `forward(self,x)`: defines the architecture of the networks and outputs the prediction, given the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:51:17.156290Z",
     "start_time": "2022-12-21T06:51:17.143256Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a + self.b * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the parameters are wraped with `nn.Parameter` which tells PyTorch they are the parameters of our model. This is important since the optimizer should know which variables to treat as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:51:21.863855Z",
     "start_time": "2022-12-21T06:51:21.845752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.2345], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2303], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = ManualLinearRegression()\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:51:23.500226Z",
     "start_time": "2022-12-21T06:51:23.451005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('a', tensor([0.2345])), ('b', tensor([0.2303]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to send the model and the data to the same device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:51:28.196043Z",
     "start_time": "2022-12-21T06:51:27.563859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([-1.1229])), ('b', tensor([-0.1863]))])\n",
      "OrderedDict([('a', tensor([-1.1229])), ('b', tensor([-0.1863]))])\n"
     ]
    }
   ],
   "source": [
    "net = ManualLinearRegression()\n",
    "print(net.state_dict())\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD([a,b], lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # forward prop\n",
    "    yhat = net(x_train_tensor)\n",
    "    loss = criterion(y_train_tensor, yhat)\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('a', tensor([-1.1229], device='cuda:0')), ('b', tensor([-0.1863], device='cuda:0'))])\n",
      "OrderedDict([('a', tensor([1.0173], device='cuda:0')), ('b', tensor([1.9844], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "net = ManualLinearRegression().to(device)\n",
    "print(net.state_dict())\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    # forward prop\n",
    "    yhat = net(x_train_tensor)\n",
    "    loss = criterion(y_train_tensor, yhat)\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.train()` sets the model to training mode. Recall some operations, such as Dropout, have distinct behaviors in training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested models\n",
    "\n",
    "PyTorch has built-in models, such as a fully connected layer we can use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:51:56.290587Z",
     "start_time": "2022-12-21T06:51:55.420305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[0.7388]])), ('linear.bias', tensor([0.1354]))])\n",
      "OrderedDict([('linear.weight', tensor([[1.9865]])), ('linear.bias', tensor([1.0093]))])\n"
     ]
    }
   ],
   "source": [
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "net = LayerLinearRegression().to(device)\n",
    "print(net.state_dict())\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    # forward prop\n",
    "    yhat = net(x_train_tensor)\n",
    "    loss = criterion(y_train_tensor, yhat)\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential models\n",
    "\n",
    "Instead of building a class, we can use a sequential model. Sequential models in PyTorch are reserved for simple networks. The sequential model can contain other models and applies them in sequence to the input to produce its output.\n",
    "\n",
    "Sequential models do not support multiple inputs or outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:52:12.435370Z",
     "start_time": "2022-12-21T06:52:11.627436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.4822]])), ('0.bias', tensor([-0.1412]))])\n",
      "OrderedDict([('0.weight', tensor([[1.9865]])), ('0.bias', tensor([1.0093]))])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "print(net.state_dict())\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    # forward prop\n",
    "    yhat = net(x_train_tensor)\n",
    "    loss = criterion(y_train_tensor, yhat)\n",
    "    # computing gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # updating parameters\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:53:14.142803Z",
     "start_time": "2022-12-21T06:53:13.308223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9865]])), ('0.bias', tensor([1.0093]))])\n"
     ]
    }
   ],
   "source": [
    "def make_train_step(net, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def train_step(x, y):\n",
    "        # Sets net to TRAIN mode\n",
    "        net.train()\n",
    "        # Makes predictions\n",
    "        yhat = net(x)\n",
    "        # Computes loss\n",
    "        loss = loss_fn(y, yhat)\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return train_step\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step = make_train_step(net, criterion, optimizer)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Checks model's parameters\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets \n",
    "\n",
    "A dataset is represented by a python class that inherits from the Dataset class. It outputs a tuple of `(inputs, labels)`. \n",
    "\n",
    "1. The `__init__(self)` method takes any argument needed to build a list of tuples (CSV file, image folder, tensors, numpy arrays, etc.). You don't need to load all the dataset in the `__init__` method if the dataset is large. \n",
    "2. `__get_item__(self, index)` allows the dataset to be indexed so it behaves like a list. It can return the corresponding slices of the pre-loaded dataset or load them on demand.\n",
    "3. `__len__(self)` returns the number of instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:53:22.847050Z",
     "start_time": "2022-12-21T06:53:22.829211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0625]), tensor([1.0950]))\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "print(train_data[0])\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset does not send the data to a device since it does not know in advanced where it needs to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "The dataloader takes the dataset as input and outputs an iterator over the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:53:25.992833Z",
     "start_time": "2022-12-21T06:53:25.973836Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:53:28.541025Z",
     "start_time": "2022-12-21T06:53:28.504536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8956],\n",
       "         [0.6617],\n",
       "         [0.8349],\n",
       "         [0.0926],\n",
       "         [0.6642],\n",
       "         [0.8810],\n",
       "         [0.9213],\n",
       "         [0.2892],\n",
       "         [0.2053],\n",
       "         [0.4276],\n",
       "         [0.1412],\n",
       "         [0.8010],\n",
       "         [0.6100],\n",
       "         [0.0705],\n",
       "         [0.2091],\n",
       "         [0.0300]]),\n",
       " tensor([[2.9005],\n",
       "         [2.3652],\n",
       "         [2.7717],\n",
       "         [1.2005],\n",
       "         [2.4571],\n",
       "         [2.8043],\n",
       "         [2.8403],\n",
       "         [1.6382],\n",
       "         [1.3711],\n",
       "         [1.9297],\n",
       "         [1.2852],\n",
       "         [2.6216],\n",
       "         [2.1991],\n",
       "         [1.1649],\n",
       "         [1.4561],\n",
       "         [1.0472]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:54:30.883782Z",
     "start_time": "2022-12-21T06:53:33.211983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[-0.4607]])), ('linear.bias', tensor([-0.1173]))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "net = LayerLinearRegression().to(device)\n",
    "train_step = make_train_step(net, criterion, optimizer)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
    "        # therefore, we need to send those mini-batches to the\n",
    "        # device where the model \"lives\"\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The inner loop gets the mini-batch from the dataloader and sends it to the correct device.\n",
    "2. In order to make use of the memory, it is better to keep the dataset as agnostic as possible.\n",
    "3. Try to keep the GPU busy with calculations and not by passing data and parameters back and forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "When evaluating the model, there are two things to consider:\n",
    "\n",
    "1. `torch.no_grad()`: it's a good practice to wrap the validation inner loop with this context manager to disable any gradient calculations.\n",
    "2. `.eval()`: setting the model to evaluation mode will adjust behavior of functions such as dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T06:55:14.200552Z",
     "start_time": "2022-12-21T06:55:14.184258Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "x = np.random.rand(1000, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(1000, 1)\n",
    "\n",
    "x_tensor = torch.from_numpy(x).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [800, 200])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T07:01:08.147789Z",
     "start_time": "2022-12-21T06:59:57.375774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[2.0222]])), ('linear.bias', tensor([0.9963]))])\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "net = LayerLinearRegression().to(device)\n",
    "lr = 1e-1\n",
    "num_epochs = 1000\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "train_step = make_train_step(net, criterion, optimizer)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        loss = train_step(x_batch, y_batch)\n",
    "        losses.append(loss)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            yhat = net(x_val)\n",
    "            val_loss = criterion(y_val, yhat)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
